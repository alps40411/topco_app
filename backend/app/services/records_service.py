# backend/app/services/records_service.py

from collections import defaultdict
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload
from sqlalchemy import select, update, delete
from datetime import date, datetime, time
from typing import List
from app.services import azure_ai_service, document_analysis_service
from app.models import work_record as models
from app.models.project import Project as ProjectModel
from app.schemas.work_record import WorkRecord as WorkRecordSchema, WorkRecordCreate, ConsolidatedReport, FileAttachment as FileAttachmentSchema, WorkRecordUpdate

async def create(db: AsyncSession, *, obj_in: WorkRecordCreate, employee_id: int) -> models.WorkRecord:
    db_obj = models.WorkRecord(
        content=obj_in.content,
        project_id=obj_in.project_id, # <-- ä½¿ç”¨ project_id
        employee_id=employee_id,
        execution_time_minutes=obj_in.execution_time_minutes,
    )

    if obj_in.files:
        for file_in in obj_in.files:
            db_file = models.FileAttachment(**file_in.model_dump())
            db_obj.files.append(db_file)

    db.add(db_obj)
    await db.commit()
    await db.refresh(db_obj)
    
    query = select(models.WorkRecord).where(models.WorkRecord.id == db_obj.id).options(
        selectinload(models.WorkRecord.files), 
        selectinload(models.WorkRecord.project) # <-- é å…ˆè¼‰å…¥å°ˆæ¡ˆè³‡è¨Š
    )
    result = await db.execute(query)
    return result.scalar_one()

async def get_multi_by_employee_today(db: AsyncSession, *, employee_id: int):
    today_start = datetime.combine(date.today(), time.min)
    today_end = datetime.combine(date.today(), time.max)
    
    query = (
        select(models.WorkRecord)
        .where(
            models.WorkRecord.employee_id == employee_id,
            models.WorkRecord.created_at >= today_start,
            models.WorkRecord.created_at <= today_end
        )
        .options(
            selectinload(models.WorkRecord.files), 
            selectinload(models.WorkRecord.project) # <-- é å…ˆè¼‰å…¥å°ˆæ¡ˆè³‡è¨Š
        )
        .order_by(models.WorkRecord.created_at.desc())
    )
    result = await db.execute(query)
    return result.scalars().all()

async def get_consolidated_today(db: AsyncSession, *, employee_id: int) -> List[ConsolidatedReport]:
    print(f"[INFO] get_consolidated_today é–‹å§‹ - employee_id: {employee_id}")
    today_records = await get_multi_by_employee_today(db=db, employee_id=employee_id)
    print(f"   [INFO] å¾žè³‡æ–™åº«å–å¾— {len(today_records)} ç­†ä»Šæ—¥è¨˜éŒ„")
    project_groups = defaultdict(lambda: {"content": [], "files": [], "record_count": 0, "project_obj": None, "ai_content": None, "total_execution_time": 0})
    
    for i, record in enumerate(today_records):
        print(f"   [INFO] è™•ç†è¨˜éŒ„ {i+1}: project_id={record.project_id}, files={len(record.files)}, execution_time={record.execution_time_minutes}min")
        if record.project:
            proj_id = record.project_id
            # åªæœ‰åœ¨ content å­˜åœ¨ä¸”ä¸ç‚ºç´”ç©ºç™½æ™‚æ‰åŠ å…¥åˆ—è¡¨
            if record.content and record.content.strip():
                project_groups[proj_id]["content"].append(record.content.strip())
            
            for j, file in enumerate(record.files):
                print(f"      ðŸ“Ž æª”æ¡ˆ {j+1}: {file.name} (is_selected_for_ai: {file.is_selected_for_ai})")
            
            project_groups[proj_id]["files"].extend(record.files)
            project_groups[proj_id]["record_count"] += 1
            project_groups[proj_id]["project_obj"] = record.project
            project_groups[proj_id]["total_execution_time"] += record.execution_time_minutes
            # ä»¥ç¬¬ä¸€ç­†ç´€éŒ„çš„ ai_content ç‚ºä¸»
            if project_groups[proj_id]["ai_content"] is None:
                project_groups[proj_id]["ai_content"] = record.ai_content
            
    consolidated_list = []
    for project_id, data in project_groups.items():
        if data["project_obj"]:
            # éŽæ¿¾æŽ‰æ‰€æœ‰å¯èƒ½çš„ç©ºå­—ä¸²ï¼Œç„¶å¾Œç”¨æ›è¡Œç¬¦é€£æŽ¥
            valid_content = [c for c in data["content"] if c]
            final_content = "\n\n".join(valid_content)

            files_schema = [FileAttachmentSchema.model_validate(f) for f in data["files"]]
            consolidated_list.append(
                ConsolidatedReport(
                    project=data["project_obj"],
                    content=final_content,
                    files=files_schema,
                    record_count=data["record_count"],
                    ai_content=data["ai_content"],
                    total_execution_time_minutes=data["total_execution_time"],
                )
            )
    return consolidated_list

# --- â†“â†“â†“ æ–°å¢žé€™å€‹å‡½å¼ â†“â†“â†“ ---
async def enhance_all_today(db: AsyncSession, *, employee_id: int) -> List[ConsolidatedReport]:
    """ä¸€éµæ½¤é£¾ä»Šå¤©æ‰€æœ‰çš„å°ˆæ¡ˆå ±å‘Š"""
    print(f"[INFO] enhance_all_today é–‹å§‹ - employee_id: {employee_id}")
    
    consolidated_reports = await get_consolidated_today(db=db, employee_id=employee_id)
    print(f"[INFO] å–å¾— {len(consolidated_reports)} å€‹å½™æ•´å ±å‘Š")
    
    for i, report in enumerate(consolidated_reports):
        print(f"ðŸš€ è™•ç†ç¬¬ {i+1} å€‹å ±å‘Š: {report.project.plan_subj_c}")
        reference_texts = []

        print(f"ðŸ“ æª¢æŸ¥ {len(report.files)} å€‹é™„ä»¶")
        for j, file_attachment in enumerate(report.files):
            print(f"   æª”æ¡ˆ {j+1}: {file_attachment.name} (is_selected_for_ai: {file_attachment.is_selected_for_ai})")
            if file_attachment.is_selected_for_ai:
                print(f"[INFO] æ­£åœ¨åˆ†æžæª”æ¡ˆ: {file_attachment.url}")
                try:
                    # å‘¼å«æ–‡ä»¶åˆ†æžæœå‹™è®€å–æª”æ¡ˆå…§å®¹
                    analyzed_text = await document_analysis_service.analyze_document_from_path(file_attachment.url)
                    print(f"[SUCCESS] æª”æ¡ˆåˆ†æžæˆåŠŸï¼Œæå–æ–‡å­—é•·åº¦: {len(analyzed_text)}")
                    reference_texts.append(analyzed_text)
                except Exception as e:
                    print(f"[ERROR] æª”æ¡ˆåˆ†æžå¤±æ•—: {str(e)}")
                    import traceback
                    traceback.print_exc()


        # å‘¼å« AI æœå‹™
        print(f"ðŸ¤– å‘¼å« Azure AI æœå‹™ - å°ˆæ¡ˆ: {report.project.plan_subj_c}, åƒè€ƒæª”æ¡ˆæ•¸: {len(reference_texts)}")
        print(f"[INFO] åŽŸå§‹å…§å®¹é•·åº¦: {len(report.content)}")
        try:
            ai_text = await azure_ai_service.get_ai_enhanced_report(
                original_content=report.content,
                project_name=report.project.plan_subj_c,
                reference_texts=reference_texts
            )
            print(f"[SUCCESS] AI æ½¤é£¾æˆåŠŸï¼Œçµæžœé•·åº¦: {len(ai_text)}")
            report.ai_content = ai_text
        except Exception as e:
            print(f"[ERROR] AI æ½¤é£¾å¤±æ•—: {str(e)}")
            import traceback
            traceback.print_exc()
            report.ai_content = report.content  # å¤±æ•—æ™‚ä½¿ç”¨åŽŸå§‹å…§å®¹
        
        # å°‡ AI çµæžœå­˜å›žè³‡æ–™åº« (åªæ›´æ–°ç¬¬ä¸€ç­†)
        today_start = datetime.combine(date.today(), time.min)
        first_record_query = select(models.WorkRecord).where(
            models.WorkRecord.employee_id == employee_id,
            models.WorkRecord.project_id == report.project.id,
            models.WorkRecord.created_at >= today_start
        ).limit(1)
        
        result = await db.execute(first_record_query)
        record_to_update = result.scalar_one_or_none()
        if record_to_update:
            record_to_update.ai_content = ai_text
            await db.commit()
            
    return consolidated_reports


async def enhance_one_today(db: AsyncSession, *, employee_id: int, project_id: int) -> ConsolidatedReport:


    # 1. å–å¾—è©²ä½¿ç”¨è€…ã€è©²å°ˆæ¡ˆä»Šå¤©çš„æ‰€æœ‰ç´€éŒ„
    today_start = datetime.combine(date.today(), time.min)
    today_end = datetime.combine(date.today(), time.max)
    
    query = (
        select(models.WorkRecord)
        .where(
            models.WorkRecord.employee_id == employee_id,
            models.WorkRecord.project_id == project_id,
            models.WorkRecord.created_at >= today_start,
            models.WorkRecord.created_at <= today_end
        )
        .options(
            selectinload(models.WorkRecord.files), 
            selectinload(models.WorkRecord.project)
        )
        .order_by(models.WorkRecord.created_at.asc()) # ç¢ºä¿ç¬¬ä¸€ç­†æ˜¯æ™‚é–“æœ€æ—©çš„
    )
    result = await db.execute(query)
    today_records = result.scalars().all()

    if not today_records:
        print("--- DEBUGçµæŸ: æœªæ‰¾åˆ°è¨˜éŒ„ï¼Œè¿”å›ž None ---")
        return None

    # 2. å½™æ•´æˆå–®ä¸€å ±å‘Šç‰©ä»¶
    project_obj = today_records[0].project
    content_list = [r.content for r in today_records]
    files_list = [f for r in today_records for f in r.files]
    
    report = ConsolidatedReport(
        project=project_obj,
        content="\n\n".join(content_list),
        files=[FileAttachmentSchema.model_validate(f) for f in files_list],
        record_count=len(today_records),
        ai_content=today_records[0].ai_content # ä½¿ç”¨ç¬¬ä¸€ç­†çš„ ai_content
    )

    # 3. å‘¼å« AI æœå‹™
    print("æº–å‚™å‘¼å« AI æœå‹™...")
    reference_texts = []
    for file_attachment in report.files:
        if file_attachment.is_selected_for_ai:
            analyzed_text = await document_analysis_service.analyze_document_from_path(file_attachment.url)
            reference_texts.append(analyzed_text)
    print(f"AI æ–‡ä»¶åˆ†æžçµæžœ: {reference_texts}")

    ai_text = await azure_ai_service.get_ai_enhanced_report(
        original_content=report.content,
        project_name=report.project.plan_subj_c,
        reference_texts=reference_texts
    )
    report.ai_content = ai_text
    print("AI æœå‹™å‘¼å«å®Œæˆ")
    
    # 4. å°‡ AI çµæžœå­˜å›žè³‡æ–™åº« (åªæ›´æ–°ç¬¬ä¸€ç­†)
    record_to_update = today_records[0]
    record_to_update.ai_content = ai_text
    await db.commit()
    await db.refresh(record_to_update)
    print("AI çµæžœå·²å­˜å›žè³‡æ–™åº«")
    print("--- DEBUGçµæŸ: æˆåŠŸè¿”å›žå ±å‘Š ---")
            
    return report



# --- â†“â†“â†“ æ–°å¢žé€™å€‹å‡½å¼ â†“â†“â†“ ---
async def update_ai_report(db: AsyncSession, *, project_id: int, ai_content: str, employee_id: int) -> bool:
    """å„²å­˜ä½¿ç”¨è€…ç·¨è¼¯å¾Œçš„ AI å…§å®¹"""
    today_start = datetime.combine(date.today(), time.min)
    
    # æ‰¾åˆ°ä»Šå¤©è©²å°ˆæ¡ˆçš„ç¬¬ä¸€ç­†ç´€éŒ„ä¾†å„²å­˜ AI å…§å®¹
    first_record_query = select(models.WorkRecord).where(
        models.WorkRecord.employee_id == employee_id,
        models.WorkRecord.project_id == project_id,
        models.WorkRecord.created_at >= today_start
    ).limit(1)

    result = await db.execute(first_record_query)
    record_to_update = result.scalar_one_or_none()
    
    if record_to_update:
        record_to_update.ai_content = ai_content
        await db.commit()
        return True
    return False



# --- â†“â†“â†“ ä½¿ç”¨é€™å€‹åŠŸèƒ½æ›´å®Œæ•´çš„ç‰ˆæœ¬è¦†è“‹èˆŠçš„å‡½å¼ â†“â†“â†“ ---
async def update_consolidated_report(db: AsyncSession, *, project_id: int, content: str, files: List, employee_id: int) -> bool:
    """
    æ›´æ–°ä¸€å€‹å°ˆæ¡ˆçš„å½™æ•´å ±å‘Šã€‚
    æ­¤ç‰ˆæœ¬å°‡æ™ºæ…§è™•ç†æª”æ¡ˆçš„æ–°å¢žã€åˆªé™¤èˆ‡ç‹€æ…‹æ›´æ–°ã€‚
    """
    today_start = datetime.combine(date.today(), time.min)
    today_end = datetime.combine(date.today(), time.max)

    query = select(models.WorkRecord).where(
        models.WorkRecord.employee_id == employee_id,
        models.WorkRecord.project_id == project_id,
        models.WorkRecord.created_at >= today_start,
        models.WorkRecord.created_at <= today_end
    ).options(selectinload(models.WorkRecord.files))
    
    result = await db.execute(query)
    records_to_update = result.scalars().all()

    if not records_to_update:
        print("DEBUG: æ²’æœ‰æ‰¾åˆ°å¯æ›´æ–°çš„è¨˜éŒ„")
        return False

    main_record = records_to_update[0]
    main_record.content = content
    
    existing_files_map = {f.url: f for f in main_record.files}
    new_files_map = {f.url: f for f in files}

    # åˆªé™¤ï¼šå­˜åœ¨æ–¼èˆŠåˆ—è¡¨ä½†ä¸å­˜åœ¨æ–¼æ–°åˆ—è¡¨çš„æª”æ¡ˆ
    for url, file_to_delete in existing_files_map.items():
        if url not in new_files_map:
            await db.delete(file_to_delete)

    # æ–°å¢žæˆ–æ›´æ–°
    for url, new_file_data in new_files_map.items():
        if url in existing_files_map:
            existing_files_map[url].is_selected_for_ai = new_file_data.is_selected_for_ai
        else:
            # å»ºç«‹æ–°æª”æ¡ˆï¼ŒæŽ’é™¤å¯èƒ½çš„ id å±¬æ€§
            file_data = new_file_data.model_dump()
            file_data.pop('id', None)  # å®‰å…¨åœ°ç§»é™¤ id å¦‚æžœå­˜åœ¨
            new_file = models.FileAttachment(**file_data)
            main_record.files.append(new_file)

    # åˆªé™¤é™¤äº†ç¬¬ä¸€ç­†ä¹‹å¤–çš„æ‰€æœ‰å¤šé¤˜ç­†è¨˜
    for record in records_to_update[1:]:
        for file_to_delete in record.files:
            await db.delete(file_to_delete)
        await db.delete(record)

    await db.commit()
    return True